{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo de um workflow de aprendizagem máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Conjunto de dados Human Activity Recognition using Smartphones*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descrição do dataset: \n",
    "https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The experiments have been carried out with a group of 30 volunteers (…). Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (…). Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity (…). The experiments have been video-recorded to label the data manually. The dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descarregar os dados do link seguinte e descompactar o ZIP: https://archive.ics.uci.edu/ml/machine-learning-databases/00240/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estrutura dos dados** (ficheiros principais):\n",
    "* Códigos das atividades: “activity_labels.txt” (2 colunas)\n",
    "* Atributos: “features.txt” (561 linhas, 2 colunas)\n",
    "* Indivíduos (treino ; teste): “train/subject_train.txt” (7352 linhas), “test/subject_test.txt” (2947 linhas), ambos com 1 coluna \n",
    "* Atributos de entrada – X (treino; teste): “train/X_train.txt” (7352 linhas), “test/X_test.txt” (2947 linhas), ambos com 561 colunas\n",
    "* Atributo de saída (atividade) – y (treino; teste): “train/y_train.txt” (7352 linhas), “test/y_test.txt” (2947 linhas), ambos com 1 coluna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variáveis:**\n",
    "For each record in the dataset it is provided: \n",
    "* A 561-feature vector with time and frequency domain variables. \n",
    "* Its activity label. \n",
    "* An identifier of the subject who carried out the experiment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao descompactar o ficheiro a pasta base será UCI HAR Dataset. Definir a variável folder abaixo com path absoluto dessa pasta. Se estiver na pasta onde está o notebook bastará: `folder = \"./UCI HAR Dataset/\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"./UCI HAR Dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = pd.read_csv(folder+'/activity_labels.txt', sep=' ', header=None, names=('ID','Activity'))\n",
    "print(activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(folder+\"/features.txt\", sep = \" \", header = None, names=('ID','Sensor'))\n",
    "print(features.shape)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_tr = pd.read_csv(folder+\"/train/subject_train.txt\", header = None, names=['SubjectID'])\n",
    "subjects_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_tst = pd.read_csv(folder+\"/test/subject_test.txt\", header = None, names=['SubjectID'])\n",
    "print(subjects_tr.shape, subjects_tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(folder+\"/train/X_train.txt\", sep = \"\\s+\", header = None)\n",
    "x_test = pd.read_csv(folder+\"/test/X_test.txt\", sep = \"\\s+\", header = None)\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(folder+\"/train/y_train.txt\", header=None, names=['ActivityID'])\n",
    "y_test = pd.read_csv(folder+\"/test/y_test.txt\", header=None, names=['ActivityID'])\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntar os conjuntos de dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_all = pd.concat([subjects_tr, subjects_tst], ignore_index=True)\n",
    "print(subjects_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = pd.concat([x_train, x_test], ignore_index = True)\n",
    "print(x_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = y_train.append(y_test, ignore_index=True)\n",
    "print(y_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colocar nomes das colunas de X como nomes das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensorNames = features['Sensor']\n",
    "x_all.columns = sensorNames\n",
    "x_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substituir códigos de atividade pela designação (string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in activities['ID']:\n",
    "    activity = activities[activities['ID'] == i]['Activity'] \n",
    "    y_all = y_all.replace({i: activity.iloc[0]})\n",
    "    \n",
    "y_all.columns = ['Activity']\n",
    "y_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntar tudo num único DataFrame e guardar num CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = pd.concat([x_all, subjects_all], axis=1)\n",
    "allXy = pd.concat([x_all, y_all], axis=1)\n",
    "print(allXy.shape)\n",
    "\n",
    "allXy.to_csv(\"HAR_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregação dos dados para um dataset mais pequeno (por indivíduo e por atividade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "grouped = allXy.groupby (['SubjectID', 'Activity']).aggregate(np.mean)\n",
    "\n",
    "print(grouped.shape)\n",
    "grouped.head()\n",
    "\n",
    "grouped.to_csv(\"HAR_grouped.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploração do conjunto de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caraterizar as distribuições de valores das variáveis de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = allXy.iloc[:,:-2]\n",
    "\n",
    "input_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caraterizar a distribuição de valores da variável de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = allXy.iloc[:,-1]\n",
    "output_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allXy.groupby(\"Activity\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar se existem valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allXy.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "sc_input = preprocessing.scale(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise não supervisionada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar um processo de PCA que explique pelo menos 80% da variabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.8)\n",
    "pca.fit(sc_input)\n",
    "X_reduced = pca.transform(sc_input)\n",
    "X_reduced.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represente a variância explicada por cada uma das primeiras 10 PCs usando um gráfico apropriado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Var. explained: %s'% str(pca.explained_variance_ratio_))\n",
    "n_pc = 10\n",
    "\n",
    "plt.bar(range(n_pc), pca.explained_variance_ratio_[0:10]*100)\n",
    "plt.xticks(range(n_pc), ['PC'+str(i) for i in range(1,n_pc+1)])\n",
    "plt.title(\"Explained variance\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construir scores plot com os resultados do PCA e comparar com variável *Activity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for act in allXy['Activity'].unique():\n",
    "    sp = allXy.index[allXy['Activity']==act]-1\n",
    "    plt.plot(X_reduced[sp,0],X_reduced[sp,1],'o',label=act)\n",
    "plt.title(\"PCA\")\n",
    "plt.legend(loc='best', shadow=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correr clustering k-means; comparar clusters com variável *Activity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k=6\n",
    "kmeans_har = KMeans(n_clusters=k, max_iter=1000)\n",
    "kmeans_har.fit(sc_input)\n",
    "labels = kmeans_har.labels_\n",
    "\n",
    "pd.crosstab(labels, allXy[\"Activity\"], rownames=['clusters'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correr clustering hierárquico usando os dados agregados e visualizar árvore resultante colorindo folhas com variável *Activity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "grouped_sc = preprocessing.scale(grouped.iloc[:,2:])\n",
    "\n",
    "Z = linkage(grouped_sc, method='single', metric='euclidean')\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "dendrogram(Z, \n",
    "\tlabels=list(grouped.index.get_level_values(1)),    \t\tleaf_rotation=90., leaf_font_size=8.)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.ylabel('distance')\n",
    "lcolors = {'STANDING':'b', \"WALKING_UPSTAIRS\":\"m\", \"LAYING\":'g', 'SITTING':'c', \"WALKING\" :\"y\", \"WALKING_DOWNSTAIRS\":\"r\"}\n",
    "ax = plt.gca()\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "  lbl.set_color(lcolors[lbl.get_text()])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendizagem máquina - modelos supervisionados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir dados em partição de treino e teste (mantendo 30% no test set); verificar distribuição nas labels no training e test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinar modelos de base com vários classificadores no conjunto de dados de treino. Avaliar cada um destes modelos com validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando o modelo mais prometedor, experimentar a seleção de atributos baseadas em testes estatísticos univariados (ANOVA), considerando uma redução para metade do número de variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando o modelo mais prometedor fazer um processo de otimização de hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criar um modelo ensemble com base nos 3 melhores modelos que experimentou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estime o erro do melhor modelo obtido no test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinar o modelo final da forma mais adequada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
